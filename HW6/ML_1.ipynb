{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "### Impementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sys\n",
    "import math\n",
    "import inspect\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ProgressBar:\n",
    "    __slots__ = ['description', 'overall', 'done', 'prevp', 'len', 'closed']\n",
    "    def __init__(self, description, overall):\n",
    "        self.description = description\n",
    "        self.overall = overall\n",
    "        self.done = 0\n",
    "        self.prevp = -1\n",
    "        self.len = 40\n",
    "        self.closed = False\n",
    "        self.__show()\n",
    "    def go(self):\n",
    "        self.done += 1\n",
    "        self.__show()\n",
    "    def __show(self):\n",
    "        p100 = int(round(100.0 * self.done / self.overall))\n",
    "        if p100 > self.prevp:\n",
    "            p = int(round(self.len * self.done / self.overall))\n",
    "            print(\"\\r%s: [%s%s] % 3d%%\" % (self.description, '#' * p, '.' * (self.len - p), p100), end='')\n",
    "            self.prevp = p100\n",
    "            if p == self.len:\n",
    "                self.close()\n",
    "    def close(self):\n",
    "        if not self.closed:\n",
    "            self.closed = True\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def arr_to_pic(a):\n",
    "    return Image.fromarray(np.uint8(a))\n",
    "\n",
    "def pic_to_arr(img):\n",
    "    if len(img.shape) == 3:\n",
    "        return np.array(img[:, :, 0])\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def png_to_arr(img):\n",
    "    img = np.array(img)\n",
    "    img = pic_to_arr(img)\n",
    "    img = np.divide(img, 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bytes_from_file(filename, chunksize=8192):\n",
    "    with open(filename, 'rb') as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunksize)\n",
    "            if chunk:\n",
    "                for b in chunk:\n",
    "                    yield b\n",
    "            else:\n",
    "                break\n",
    "\n",
    "def read_train_labels(filename, need_buben):\n",
    "    all_bytes = list(bytes_from_file(filename))\n",
    "    def read(idx=[0]):\n",
    "        idx[0] += 1\n",
    "        return all_bytes[idx[0] - 1]\n",
    "    def read_i32():\n",
    "        return (int(read()) << 24) + (int(read()) << 16) + (int(read()) << 8) + int(read())\n",
    "    buben = read_i32()\n",
    "    assert \"buben must be %d\" % need_buben, buben == need_buben\n",
    "    count = read_i32()\n",
    "    labels = [read() for _ in range(count)]\n",
    "    return np.array(labels)\n",
    "\n",
    "def read_train_images(filename, need_buben):\n",
    "    all_bytes = list(bytes_from_file(filename))\n",
    "    def read(idx=[0]):\n",
    "        idx[0] += 1\n",
    "        return all_bytes[idx[0] - 1]\n",
    "    def read_i32():\n",
    "        return (int(read()) << 24) + (int(read()) << 16) + (int(read()) << 8) + int(read())\n",
    "    buben = read_i32()\n",
    "    assert \"buben must be %d\" % need_buben, buben == need_buben\n",
    "    count = read_i32()\n",
    "    rows = read_i32()\n",
    "    columns = read_i32()\n",
    "    print(count, rows, columns, count * rows * columns, file=sys.stderr)\n",
    "    imgs = np.zeros((count, rows, columns))\n",
    "    for x in range(count):\n",
    "        for i in range(rows):\n",
    "            for j in range(columns):\n",
    "                imgs[x, i, j] = read() / 255\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_pics(images):\n",
    "    for i, img in enumerate(images):\n",
    "        arr_to_pic(img).save('pics/test_pic%02d.png' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, func, ws):\n",
    "        self.inodes = []\n",
    "        self.onodes = []\n",
    "        self.value = None\n",
    "        self.func = func\n",
    "        self.ws = ws\n",
    "    def get(self):\n",
    "        if self.value == None:\n",
    "            assert len(self.inodes) == len(self.ws)\n",
    "            gets = [n.get() for n in self.inodes]\n",
    "            arg = sum(w * x for (w, x) in zip(self.ws, gets))\n",
    "            self.value = self.func(arg)\n",
    "        return self.value\n",
    "    def clear(self):\n",
    "        self.value = None\n",
    "    def add_onode(self, onode):\n",
    "        self.onodes.append(onode)\n",
    "    def add_inode(self, inode):\n",
    "        self.inodes.append(inode)\n",
    "    def isbayes(self):\n",
    "        return False\n",
    "    def dump(self, file):\n",
    "        print('node %s' % ' '.join(map(str, self.ws)), file=file)\n",
    "\n",
    "class InputNode:\n",
    "    def __init__(self, i, j):\n",
    "        self.i = i\n",
    "        self.j = j\n",
    "        self.value = None\n",
    "    def get(self, img=None):\n",
    "        if self.value == None:\n",
    "            self.value = img[self.i, self.j]\n",
    "        return self.value\n",
    "    def clear(self):\n",
    "        self.value = None\n",
    "    def add_onode(self, onode):\n",
    "        pass\n",
    "    def add_inode(self, inode):\n",
    "        pass\n",
    "    def isbayes(self):\n",
    "        return False\n",
    "    def dump(self, file):\n",
    "        print('input %d %d' % (self.i, self.j), file=file)\n",
    "\n",
    "class BayesUnit:\n",
    "    def get(*args):\n",
    "        return 1\n",
    "    def clear():\n",
    "        pass\n",
    "    def add_onode(onode):\n",
    "        pass\n",
    "    def add_inode(inode):\n",
    "        pass\n",
    "    def isbayes():\n",
    "        return True\n",
    "    def dump(file):\n",
    "        print('bayes', file=file)\n",
    "\n",
    "def nodepipe(inode, onode):\n",
    "    inode.add_onode(onode)\n",
    "    onode.add_inode(inode)\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, nodes):\n",
    "        self.nodes = nodes\n",
    "    def add_node(self, node):\n",
    "        self.nodes.append(node)\n",
    "    def calc(self, *args, **kwargs):\n",
    "        f = lambda node: node.get(*args)\n",
    "        pool = kwargs['pool'] if 'pool' in kwargs.keys() else None\n",
    "        if pool != None:\n",
    "            return list(pool.map(f, self.nodes))\n",
    "        else:\n",
    "            return [f(node) for node in self.nodes]\n",
    "    def clear(self):\n",
    "        for node in self.nodes:\n",
    "            node.clear()\n",
    "    def size(self):\n",
    "        return len(self.nodes)\n",
    "\n",
    "def layerpipe(ilayer, olayer):\n",
    "    for inode in ilayer.nodes:\n",
    "        for onode in olayer.nodes:\n",
    "            nodepipe(inode, onode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def gaussian(mean, variance):\n",
    "    std = np.sqrt(variance)\n",
    "    return lambda: np.random.normal(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_net(rows, columns, mid_size):\n",
    "    size = rows * columns\n",
    "    layers = []\n",
    "    \n",
    "    input_layer = Layer([])\n",
    "    input_layer.add_node(BayesUnit)\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            node = InputNode(i, j)\n",
    "            input_layer.add_node(node)\n",
    "    layers.append(input_layer)\n",
    "            \n",
    "    mid_layer = Layer([])\n",
    "    mid_layer.add_node(BayesUnit)\n",
    "    for i in range(mid_size):\n",
    "        csize = 1 + layers[-1].size()\n",
    "        node = Node(sigmoid, [0] * csize)\n",
    "        mid_layer.add_node(node)\n",
    "    layers.append(mid_layer)\n",
    "    \n",
    "    output_layer = Layer([])\n",
    "    for i in range(10):\n",
    "        csize = 1 + layers[-1].size()\n",
    "        node = Node(sigmoid, [0] * csize)\n",
    "        output_layer.add_node(node)\n",
    "    layers.append(output_layer)\n",
    "    \n",
    "    for i in range(len(layers) - 1):\n",
    "        layerpipe(layers[i], layers[i + 1])\n",
    "        \n",
    "    np.random.seed(1321)\n",
    "    for layer in layers:\n",
    "        for node in layer.nodes:\n",
    "            if isinstance(node, Node):\n",
    "                variance = 2 / (len(node.inodes) + len(node.onodes))\n",
    "                gen = gaussian(0, variance)\n",
    "                node.ws = [gen() for _ in node.inodes]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing.dummy\n",
    "thread_pool = multiprocessing.dummy.Pool(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_net(layers, image):\n",
    "    for layer in layers:\n",
    "        layer.clear()\n",
    "    layers[0].calc(image, pool=thread_pool)\n",
    "    return np.array(layers[-1].calc(pool=thread_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_local(layers, img, ans, lrate=0.1):\n",
    "    cur_res = apply_net(layers, img)\n",
    "    sig1 = np.zeros(cur_res.shape)\n",
    "    for i in range(cur_res.shape[0]):\n",
    "        sig1[i] = cur_res[i] * (1 - cur_res[i])\n",
    "\n",
    "    epsM = cur_res - ans\n",
    "    epsH = np.zeros(len(layers[-2].nodes))\n",
    "    for h, pnode in enumerate(layers[-2].nodes):\n",
    "        for m, node in enumerate(layers[-1].nodes):\n",
    "            if node.isbayes():\n",
    "                continue\n",
    "            epsH[h] += epsM[m] * node.ws[h] * sig1[m]\n",
    "\n",
    "    for m, node in enumerate(layers[-1].nodes):\n",
    "        if node.isbayes():\n",
    "            continue\n",
    "        for h, pnode, in enumerate(layers[-2].nodes):\n",
    "            node.ws[h] -= lrate * epsM[m] * sig1[m] * pnode.get()\n",
    "    \n",
    "    for h, pnode in enumerate(layers[-2].nodes):\n",
    "        if pnode.isbayes():\n",
    "            continue\n",
    "        sigma = pnode.get() * (1 - pnode.get())\n",
    "        for j, jnode in enumerate(layers[-3].nodes):\n",
    "            pnode.ws[j] -= lrate * epsH[h] * jnode.get() * sigma\n",
    "    return layers\n",
    "            \n",
    "def train_net(layers, images, answers, bsize=128, iters=1, epochs=1, lrate=0.1):\n",
    "    cnt = len(images)\n",
    "    bs, anss = [], []\n",
    "    for i in range(0, cnt, bsize):\n",
    "        j = min(i + bsize, cnt)\n",
    "        bs.append(images[i : j, :])\n",
    "        anss.append(answers[i : j, :])\n",
    "    pbar = ProgressBar('Train net', epochs * len(images) * iters)\n",
    "    for ep in range(epochs):\n",
    "        for b, a in zip(bs, anss):\n",
    "            for it in range(iters):\n",
    "                for img, ans in zip(b, a):\n",
    "                    pbar.go()\n",
    "                    train_local(layers, img, ans, lrate)\n",
    "    pbar.close()\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_net(net, file):\n",
    "    print('netsize', len(net), file=file)\n",
    "    for layer in net:\n",
    "        print('layersize', len(layer.nodes), file=file)\n",
    "        for node in layer.nodes:\n",
    "            node.dump(file)\n",
    "\n",
    "def load_net(file, func):\n",
    "    cw, cl = file.readline().strip().split()\n",
    "    if cw != 'netsize':\n",
    "        raise RuntimeError('\\'netsize\\' excepted, %r found' % cw)\n",
    "    cl = int(cl)\n",
    "    net = []\n",
    "    for _ in range(cl):\n",
    "        cw, cnt = file.readline().strip().split()\n",
    "        if cw != 'layersize':\n",
    "            raise RuntimeError('\\'layersize\\' excepted, %r found' % cw)\n",
    "        cnt = int(cnt)\n",
    "        layer = Layer([])\n",
    "        for __ in range(cnt):\n",
    "            tokens = file.readline().strip().split()\n",
    "            if tokens[0] == 'node':\n",
    "                ws = list(map(float, tokens[1:]))\n",
    "                layer.add_node(Node(func, ws))\n",
    "            elif tokens[0] == 'input':\n",
    "                i, j = map(int, tokens[1:])\n",
    "                layer.add_node(InputNode(i, j))\n",
    "            elif tokens[0] == 'bayes':\n",
    "                layer.add_node(BayesUnit)\n",
    "            else:\n",
    "                raise RuntimeError('unknown first token: %s' % tokens[0])\n",
    "        net.append(layer)\n",
    "    for i in range(len(net) - 1):\n",
    "        layerpipe(net[i], net[i + 1])\n",
    "    return net\n",
    "\n",
    "def test_dump(net):\n",
    "    fn = 'test.txt'\n",
    "    with open(fn, 'w') as f:\n",
    "        dump_net(net, f)\n",
    "    with open(fn) as f:\n",
    "        new_net = load_net(f, sigmoid)\n",
    "    for l1, l2 in zip(net, new_net):\n",
    "        assert(len(l1.nodes) == len(l2.nodes))\n",
    "        for n1, n2 in zip(l1.nodes, l2.nodes):\n",
    "            if isinstance(n1, Node):\n",
    "                assert isinstance(n2, Node)\n",
    "                assert len(n1.inodes) == len(n2.inodes)\n",
    "                assert len(n1.onodes) == len(n2.onodes)\n",
    "                diff = np.array(n1.ws) - np.array(n2.ws)\n",
    "                assert np.absolute(diff).max() < 1e-7\n",
    "            elif isinstance(n1, InputNode):\n",
    "                assert isinstance(n2, InputNode)\n",
    "                assert n1.i == n2.i and n1.j == n2.j\n",
    "            else:\n",
    "                assert n1 == BayesUnit\n",
    "                assert n2 == BayesUnit\n",
    "    print(\"Ok test\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_net(images, labels, mid_size=50, iters=1, lrate=0.1):\n",
    "    answers = np.zeros((labels.shape[0], 10))\n",
    "    for i in range(labels.shape[0]):\n",
    "        answers[i, labels[i]] = 1\n",
    "    rows, columns = images[0].shape\n",
    "    layers = build_net(rows, columns, mid_size)\n",
    "    layers = train_net(layers, images, answers, iters=iters, lrate=lrate)\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_net(net, images, labels):\n",
    "    goods, overall = 0, labels.shape[0]\n",
    "    pbar = ProgressBar('Test net', overall)\n",
    "    for i in range(overall):\n",
    "        result = np.argmax(apply_net(net, images[i]))\n",
    "        if result == labels[i]:\n",
    "            goods += 1\n",
    "        pbar.go()\n",
    "    pbar.close()\n",
    "    print(\"ok %.3f%% (%d out of %d)\" % (goods / overall * 100, goods, overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60000 28 28 47040000\n",
      "10000 28 28 7840000\n"
     ]
    }
   ],
   "source": [
    "labels = read_train_labels('train-labels.idx1-ubyte', 2049)\n",
    "images = read_train_images('train-images.idx3-ubyte', 2051)\n",
    "test_labels = read_train_labels('t10k-labels.idx1-ubyte', 2049)\n",
    "test_images = read_train_images('t10k-images.idx3-ubyte', 2051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train net: [########################################]  100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ok test\n"
     ]
    }
   ],
   "source": [
    "test_dump(make_net(images[:10], labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 1000\n",
    "net = make_net(images[:cnt], labels[:cnt], iters=2, lrate=0.3)\n",
    "test_net(net, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seven: Result is 7\n",
      "three-1: Result is 3\n",
      "three: Result is 3\n"
     ]
    }
   ],
   "source": [
    "def apply_on_pic(net, img):\n",
    "    img = png_to_arr(img)\n",
    "    result = np.argmax(apply_net(net, img))\n",
    "    print(\"Result is %d\" % result)\n",
    "    \n",
    "with open('nets/net-all-0.4.net') as file:\n",
    "    net = load_net(file, sigmoid)\n",
    "for path in os.listdir('pics/'):\n",
    "    print(path.split('.')[0] + \": \", end='')\n",
    "    apply_on_pic(net, Image.open('pics/' + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
